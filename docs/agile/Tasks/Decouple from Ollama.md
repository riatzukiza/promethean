## ğŸ› ï¸ Task: Add Ollama formally to pipeline

It's difficult to get the system running for codex and CI/CD for them to properly run integration tests, or  just to sanity  test that it starts.



---

## ğŸ¯ Goals

- Allow the system to source models from a diverse set of LLM providers
- Open up the option to train custom LLM more easily for the system

---

## ğŸ“¦ Requirements

- System Can use any model from:
	- ollama
	- HuggingFace
	- ...npu/open vino?

---

## ğŸ“‹ Subtasks

- [ ] Write driver classes for llm service
- [ ] 


---

## ğŸ”— Related Epics

#framework-core

---

## â›“ï¸ Blocked By

Nothing

## â›“ï¸ Blocks

Nothing

---

## ğŸ” Relevant Links

- [kanban](../boards/kanban.md)
#prompt-refinement
