## 🛠️ Task: Add Ollama formally to pipeline

It's difficult to get the system running for codex and CI/CD for them to properly run integration tests, or  just to sanity  test that it starts.



---

## 🎯 Goals

- Allow the system to source models from a diverse set of LLM providers
- Open up the option to train custom LLM more easily for the system

---

## 📦 Requirements

- System Can use any model from:
	- ollama
	- HuggingFace
	- ...npu/open vino?

---

## 📋 Subtasks

- [ ] Write driver classes for llm service
- [ ] 


---

## 🔗 Related Epics

#framework-core

---

## ⛓️ Blocked By

Nothing

## ⛓️ Blocks

Nothing

---

## 🔍 Relevant Links

- [kanban](../boards/kanban.md)
#prompt-refinement
